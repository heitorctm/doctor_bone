{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"https://uol.unifor.br/acesso/app/autenticacao/assets/img/logos/icon-unifor.svg\" width=45 height=45>\n",
    "<img src=\"https://vortex.unifor.br/assets/logos/v1.png\" width=45 height=45>\n",
    "<font size=5 color=k>\n",
    "<br><br>\n",
    "<font size=5 color=k><strong>Projeto:</strong> Doctor Bone\n",
    "\n",
    "<strong>Etapa:</strong> Treinamento e teste\n",
    "\n",
    "<strong>Autoria:</strong> Heitor Teixeira\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 0 - Bibliotecas e configuração de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import GPUtil\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop # type: ignore\n",
    "from tensorflow.keras.losses import MeanAbsoluteError # type: ignore\n",
    "from auxiliar.dataset import criar_dataset\n",
    "from auxiliar.avaliar import avaliar_modelo\n",
    "from auxiliar.callbacks import callbacks\n",
    "from auxiliar.arquiteturas import custom_model\n",
    "\n",
    "tf_gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "if tf_gpu:\n",
    "    try:\n",
    "        nome_gpu = GPUtil.getGPUs()\n",
    "        print(\"GPU configurada: \", nome_gpu[0].name)\n",
    "        tf.config.experimental.set_memory_growth(tf_gpu[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 1 - Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ao lado o batchsize que comporta na minha placa de vídeo, adequa com o que couber.\n",
    "'''\n",
    "\n",
    "redes = [\n",
    "        'InceptionV3', # 100\n",
    "        'InceptionResNetV2', # 50\n",
    "        'EfficientNetV2L', # 5\n",
    "        'EfficientNetV2S', # 16\n",
    "        'ResNet152V2', # 50\n",
    "        'EfficientNetV2M', # 10\n",
    "        'EfficientNetV2B3', # 50\n",
    "        'ResNet50V2', # 150\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parametros iniciais para o treinamento, incluindo o identificador de rodada,\n",
    "a rede a ser usada, o batch size e o numero de epocas. definir tambem a funcao de perda, \n",
    "o otimizador e outros parametros relevantes.\n",
    "\n",
    "lembrar de ajustar a lr quando mudar de otimizador e rede. quanto maior e mais camadas tiver uma rede, menor deve ser a lr\n",
    "tem a questão de explodir os gradientes e estabilidade. quanto mais profunda for a rede menor a lr.\n",
    "na maioria das vezes da pra usar o adam com lr = 0.001. mas se for prauma efficientnet M L ou XL é bom dar uma diminuida.\n",
    "'''\n",
    "\n",
    "seed=2220276\n",
    "id_rodada = 0\n",
    "rede = redes[3]\n",
    "batch_size = 16\n",
    "\n",
    "epocas = 100\n",
    "loss = MeanAbsoluteError() \n",
    "nome_loss = 'mae' # uma string pra salvar no csv\n",
    "lr = 0.0001\n",
    "\n",
    "'''\n",
    "aqui tao os parametros da arquitetura do modelo. alguns desses parametros fazem nda,\n",
    "é so uma string pra salvar no log e a gente saber que aquele resultado tinha determinada conf.\n",
    "daria pra colocar uma condicional na funcao de avaliar e gravar o csv? dava, mas dava mais trabalho\n",
    "'''\n",
    "\n",
    "otimizador = Adam(learning_rate = lr) # Adam, SGD, RMSprop\n",
    "nome_otimizador = 'adam' # uma string pra salvar no csv\n",
    "\n",
    "attention = 'cbam' # 'se' ou 'cbam'. as 2 camadas de attention que adicionei caso queria treinar com\n",
    "camada_pooling = 'global_avg' # 'avg', 'max', 'global_max', 'global_avg', flatten(sem pooling)\n",
    "imagenet = 'imagenet-21k' # imagenet, imagenet-21k, imagenet-21k-ft1k, os modelos efficient net podem ser treinados na 21k\n",
    "\n",
    "'''\n",
    "proejetei pra aceitar ate 5 camadas densas, é so ajustar que da pra aumentar. so acho que nao precisa\n",
    "'''\n",
    "\n",
    "denses = [1024, 256, 256] \n",
    "dropouts = [0, 0, 0] \n",
    "\n",
    "data_aug = False\n",
    "\n",
    "check_best = True\n",
    "check_10 = True\n",
    "early_stop = True\n",
    "log = True\n",
    "reduce_lr = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 2 - Importando dados e criando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "carregar os dados de treino, validacao e teste a partir de um arquivo csv e dividir em conjuntos\n",
    "de treino, validacao e teste com proporcoes definidas.\n",
    "\n",
    "aqui eu juntei todos os dados em um so csv e em uma so pasta. no RSNA existem 3 dados, 3 arquivos zips.\n",
    "1 de treino e mais 2 de validacao. juntei todos e adicionei mais outras 1388 imagens jpg que achei.\n",
    "so depois de tudo junto que fiz a divisao do que é treino, validacao ou teste\n",
    "'''\n",
    "\n",
    "dir_dados = '../treino-validacao-teste.csv'\n",
    "dir_imagens = '../imagens/imagens'\n",
    "\n",
    "dir_modelos_salvos = f'./redes/{rede}/modelos_salvos/{rede}-{id_rodada}_epoca_{{epoch:02d}}.hdf5'\n",
    "dir_csv_log_treino = f'./redes/{rede}/log_treino/{rede}-{id_rodada}_treinamento_log.csv'\n",
    "\n",
    "teste_size = 0.15\n",
    "val_size = 0.10\n",
    "\n",
    "dados_treino = pd.read_csv(dir_dados)\n",
    "\n",
    "dados_treino, dados_teste = train_test_split(\n",
    "    dados_treino, \n",
    "    random_state=seed,\n",
    "    test_size = teste_size,\n",
    ")\n",
    "\n",
    "dados_treino, dados_validacao = train_test_split(\n",
    "    dados_treino,\n",
    "    random_state=seed,\n",
    "    test_size = val_size,\n",
    ")\n",
    "\n",
    "print(len(dados_treino))\n",
    "print(len(dados_validacao))\n",
    "print(len(dados_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset é uma colecaoo estruturada de dados onde cada linha representa uma observação e cada coluna representa um atributo. \n",
    "é como se fosse um dado tabular, mas ele é otiimzados pro treinamento\n",
    "diferenca de um dataframe:\n",
    "\n",
    "a funcao ja foi comentada nos arquivos auxiliares\n",
    "'''\n",
    "\n",
    "dataset_treino = criar_dataset(\n",
    "    dataframe = dados_treino,\n",
    "    diretorio = dir_imagens,\n",
    "    batch_size = batch_size,\n",
    "    rede = rede,\n",
    "    shuffle = True,\n",
    "    data_aug = data_aug\n",
    ")\n",
    "\n",
    "dataset_validacao = criar_dataset(\n",
    "    dataframe = dados_validacao,\n",
    "    diretorio = dir_imagens,\n",
    "    batch_size = batch_size,\n",
    "    rede = rede,\n",
    ")\n",
    "\n",
    "dataset_teste = criar_dataset(\n",
    "    dataframe = dados_teste,\n",
    "    diretorio = dir_imagens,\n",
    "    batch_size = batch_size,\n",
    "    rede = rede,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 3 - Modelando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja foi comentado nos arquivos auxiliares\n",
    "\n",
    "model = custom_model(\n",
    "    rede= rede,\n",
    "    loss = loss,\n",
    "    weights = imagenet,\n",
    "    otimizador = otimizador, \n",
    "    attention = attention, \n",
    "    denses = denses,\n",
    "    dropouts = dropouts,\n",
    "    pooling = camada_pooling\n",
    ")\n",
    "\n",
    "'''\n",
    "aqui é so pra gente ter nocao do quao grande é o modelo que a gente vai treinar.\n",
    "vai me dizer quantas camadas o modelo vai ter e sumario bem direitinho dele\n",
    "'''\n",
    "num_layers = len(model.layers)\n",
    "print(f'camadas no modelo: {num_layers}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja foi comentado nos arquivos auxiliares\n",
    "\n",
    "callbacks_treino = callbacks(\n",
    "    dir_modelos_salvos = dir_modelos_salvos, \n",
    "    dir_csv_log = dir_csv_log_treino,\n",
    "    check_best = check_best, \n",
    "    check_15 = check_10, \n",
    "    early_stop = early_stop, \n",
    "    log = log, \n",
    "    reduce_lr = reduce_lr,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 4 - Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja foi comentado nos arquivos auxiliares\n",
    "\n",
    "steps_per_epoch = len(dados_treino) // batch_size\n",
    "validation_steps=len(dados_validacao) // batch_size\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(\n",
    "    dataset_treino, \n",
    "    validation_data = dataset_validacao, \n",
    "    steps_per_epoch = steps_per_epoch, \n",
    "    validation_steps = validation_steps, \n",
    "    epochs = epocas,\n",
    "    callbacks=callbacks_treino\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "tempo_treino = end_time - start_time\n",
    "print(tempo_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "<font size=5 color='blue'> 5 - Avaliar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja foi comentado nos arquivos auxiliares\n",
    "\n",
    "avaliar_modelo(\n",
    "    model=model,\n",
    "    rede=rede,\n",
    "    id_rodada=id_rodada,  \n",
    "    dataset_teste=dataset_teste,\n",
    "    dados_teste=dados_teste,\n",
    "    batch_size=batch_size,\n",
    "    imagenet=imagenet,\n",
    "    data_aug=data_aug,\n",
    "    nome_otimizador=nome_otimizador,\n",
    "    nome_loss=nome_loss,\n",
    "    lr=lr,\n",
    "    attention=attention,\n",
    "    camada_pooling=camada_pooling,\n",
    "    denses=denses,\n",
    "    dropouts=dropouts,\n",
    "    tempo_treino=tempo_treino\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-ciencia_de_dados",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
